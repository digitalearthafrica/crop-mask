{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing analysts accuracy at labelling reference data\n",
    "\n",
    "Collect Earth Online is being used as a tool for collecting cropland reference data.  The sample data contains 'known' labels seeded among the other samples. This script will compare the known test labels (GFSAD's validation data), against the user collected labels.\n",
    "\n",
    "Inputs will be:\n",
    "\n",
    "1. `ceo-data....csv` : The results from collecting training data in the CEO tool\n",
    "\n",
    "Output will be:\n",
    "1. A `confusion error matrix` containing Overall, Producer's, and User's accuracy, along with the F1 score.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/training_validation/collect_earth/central/'\n",
    "csv = 'data/training_validation/collect_earth/central/ceo-Cropland-Reference-Data-Acquisition---Central---Victor-sample-data-2020-12-16.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground truth shapefile\n",
    "df = pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>smpl_sampleid</th>\n",
       "      <th>smpl_gfsad_samp</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.807380</td>\n",
       "      <td>-1.009527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>non-crop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.599344</td>\n",
       "      <td>-1.476830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>non-crop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.083868</td>\n",
       "      <td>-4.524275</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-crop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.336722</td>\n",
       "      <td>-4.617520</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-crop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.549448</td>\n",
       "      <td>-4.848208</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-crop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lon       lat  smpl_sampleid  smpl_gfsad_samp  Actual Prediction\n",
       "0  14.807380 -1.009527              0                0       1   non-crop\n",
       "1  17.599344 -1.476830              1                0       1   non-crop\n",
       "2  12.083868 -4.524275              2                0       2   non-crop\n",
       "3  27.336722 -4.617520              3                0       2   non-crop\n",
       "4  28.549448 -4.848208              4                0       2   non-crop"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this line if testing sample:\n",
    "# df = df[['lon', 'lat', 'smpl_class','Is the sample area entirely: crop, non-crop, mixed, or unsure?']]\n",
    "\n",
    "#This line if entire dataset:\n",
    "df = df[['lon', 'lat', 'smpl_sampleid', 'smpl_gfsad_samp','smpl_class','Is the sample area entirely: crop, non-crop, mixed, or unsure?']]\n",
    "\n",
    "#rename columns\n",
    "df = df.rename(columns={'Is the sample area entirely: crop, non-crop, mixed, or unsure?':'Prediction',\n",
    "                        'smpl_class':'Actual'})\n",
    "\n",
    "#remove nan rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "If this is the `test sample` (first 50-100 samples used for training analysts) then ignore the following cell.\n",
    "\n",
    "If this is the reference data sample (2100) points, then run the cell below to extract the GFSAD validation samples before running the rest of the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "#This line if entire dataset:\n",
    "# df = df[['lon', 'lat', 'smpl_sampleid', 'smpl_gfsad_samp','smpl_class','Is the sample area entirely: crop, non-crop, mixed, or unsure?']]\n",
    "\n",
    "#rename columns\n",
    "df = df.rename(columns={'Is the sample area entirely: crop, non-crop, mixed, or unsure?':'Prediction',\n",
    "                        'smpl_class':'Actual'})\n",
    "\n",
    "df = df[df['smpl_gfsad_samp']==True]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify prediction & actual columns\n",
    "\n",
    "1 = crop, \n",
    "0 = non-crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Prediction'] = np.where(df['Prediction']=='non-crop', 0, df['Prediction'])\n",
    "df['Prediction'] = np.where(df['Prediction']=='crop', 1, df['Prediction'])\n",
    "\n",
    "df['Actual'] = np.where(df['Actual']==1, 0, df['Actual'])\n",
    "df['Actual'] = np.where(df['Actual']==2, 1, df['Actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a confusion matrix with all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>mixed</th>\n",
       "      <th>unsure</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction   0   1  mixed  unsure  All\n",
       "Actual                                \n",
       "0           22   0      1       0   23\n",
       "1            4  10      0       9   23\n",
       "All         26  10      1       9   46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(df['Actual'],\n",
    "                               df['Prediction'],\n",
    "                               rownames=['Actual'],\n",
    "                               colnames=['Prediction'],\n",
    "                               margins=True)\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify into a binary assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 46\n",
      "Number of 'mixed' samples: 1\n",
      "Number of 'unsure' samples: 9\n",
      "Dropping 'mixed' and 'unsure' samples\n"
     ]
    }
   ],
   "source": [
    "counts = df.groupby('Prediction').count()\n",
    "\n",
    "print(\"Total number of samples: \" + str(len(df)))\n",
    "print(\"Number of 'mixed' samples: \"+ str(counts[counts.index=='mixed']['Actual'].values[0]))\n",
    "print(\"Number of 'unsure' samples: \"+ str(counts[counts.index=='unsure']['Actual'].values[0]))\n",
    "\n",
    "print(\"Dropping 'mixed' and 'unsure' samples\")\n",
    "\n",
    "df = df.drop(df[df['Prediction']=='mixed'].index)\n",
    "df = df.drop(df[df['Prediction']=='unsure'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Recreate confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction   0   1  All\n",
       "Actual                 \n",
       "0           22   0   22\n",
       "1            4  10   14\n",
       "All         26  10   36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(df['Actual'],\n",
    "                               df['Prediction'],\n",
    "                               rownames=['Actual'],\n",
    "                               colnames=['Prediction'],\n",
    "                               margins=True)\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate User's and Producer's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Producer's Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix[\"Producer's\"] = [confusion_matrix.loc[0, 0] / confusion_matrix.loc[0, 'All'] * 100,\n",
    "                              confusion_matrix.loc[1, 1] / confusion_matrix.loc[1, 'All'] * 100,\n",
    "                              np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`User's Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_accuracy = pd.Series([confusion_matrix[0][0] / confusion_matrix[0]['All'] * 100,\n",
    "                                confusion_matrix[1][1] / confusion_matrix[1]['All'] * 100]\n",
    "                         ).rename(\"User's\")\n",
    "\n",
    "confusion_matrix = confusion_matrix.append(users_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Overall Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.loc[\"User's\",\"Producer's\"] = (confusion_matrix.loc[0, 0] + \n",
    "                                                confusion_matrix.loc[1, 1]) / confusion_matrix.loc['All', 'All'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`F1 Score`\n",
    "\n",
    "The F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall), and is calculated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Fscore} = 2 \\times \\frac{\\text{UA} \\times \\text{PA}}{\\text{UA} + \\text{PA}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where UA = Users Accuracy, and PA = Producer's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = pd.Series([(2*(confusion_matrix.loc[\"User's\", 0]*confusion_matrix.loc[0, \"Producer's\"]) / (confusion_matrix.loc[\"User's\", 0]+confusion_matrix.loc[0, \"Producer's\"])) / 100,\n",
    "                    f1_score(df['Actual'].astype(np.int8), df['Prediction'].astype(np.int8), average='binary')]\n",
    "                         ).rename(\"F-score\")\n",
    "\n",
    "confusion_matrix = confusion_matrix.append(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Confusion Matrix\n",
    "\n",
    "* Limit decimal places,\n",
    "* Add readable class names\n",
    "* Remove non-sensical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "confusion_matrix = confusion_matrix.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename booleans to class names\n",
    "confusion_matrix = confusion_matrix.rename(columns={0:'Non-crop', 1:'Crop', 'All':'Total'},\n",
    "                                            index={0:'Non-crop', 1:'Crop', 'All':'Total'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the nonsensical values in the table\n",
    "confusion_matrix.loc[\"User's\", 'Total'] = '--'\n",
    "confusion_matrix.loc['Total', \"Producer's\"] = '--'\n",
    "confusion_matrix.loc[\"F-score\", 'Total'] = '--'\n",
    "confusion_matrix.loc[\"F-score\", \"Producer's\"] = '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>Non-crop</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Total</th>\n",
       "      <th>Producer's</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-crop</th>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crop</th>\n",
       "      <td>4.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>14</td>\n",
       "      <td>71.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>26.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>36</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User's</th>\n",
       "      <td>84.62</td>\n",
       "      <td>100.00</td>\n",
       "      <td>--</td>\n",
       "      <td>88.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.83</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction  Non-crop    Crop Total Producer's\n",
       "Actual                                       \n",
       "Non-crop       22.00    0.00    22        100\n",
       "Crop            4.00   10.00    14      71.43\n",
       "Total          26.00   10.00    36         --\n",
       "User's         84.62  100.00    --      88.89\n",
       "F-score         0.92    0.83    --         --"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.to_csv(folder+ 'reference_data_accuracy_results_Victor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Finding difference between GFSAD and analysts labels\n",
    "\n",
    "reclassify their label to match 1,2 labels of GFSAD, find where they differ, filter to only the crop, non-crop difference, export a shapefile suitable to go into CEO for re-training on incorrect labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/training_validation/collect_earth/western/'\n",
    "csv = 'data/training_validation/collect_earth/western/ceo-Cropland-Reference-Data-Testing-Sample---Western-Region---Yadjemi-sample-data-2020-12-09.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open\n",
    "df = pd.read_csv(csv)\n",
    "\n",
    "#--These lines if entire dataset:------------\n",
    "df = df[['lon', 'lat', 'smpl_sampleid', 'smpl_gfsad_samp','smpl_class','Is the sample area entirely: crop, non-crop, mixed, or unsure?']]\n",
    "#rename columns\n",
    "df = df.rename(columns={'Is the sample area entirely: crop, non-crop, mixed, or unsure?':'Prediction',\n",
    "                        'smpl_class':'Actual'})\n",
    "df = df[df['smpl_gfsad_samp']==True]\n",
    "print(len(df))\n",
    "#--------------------------------------------\n",
    "\n",
    "# #only the columns we care about\n",
    "# df = df[['lon', 'lat', 'smpl_class','Is the sample area entirely: crop, non-crop, mixed, or unsure?']]\n",
    "# #rename\n",
    "# df = df.rename(columns={'Is the sample area entirely: crop, non-crop, mixed, or unsure?':'Prediction',\n",
    "#                         'smpl_class':'Actual'})\n",
    "\n",
    "#reclassify so classes match\n",
    "df['Prediction'] = np.where(df['Prediction']=='non-crop', 0, df['Prediction'])\n",
    "df['Prediction'] = np.where(df['Prediction']=='crop', 1, df['Prediction'])\n",
    "df['Actual'] = np.where(df['Actual']==1, 0, df['Actual'])\n",
    "df['Actual'] = np.where(df['Actual']==2, 1, df['Actual'])\n",
    "\n",
    "#drop mixed and unsure labels\n",
    "df = df.drop(df[df['Prediction']=='mixed'].index)\n",
    "df = df.drop(df[df['Prediction']=='unsure'].index)\n",
    "\n",
    "# index out the rows that differ\n",
    "df_dif = df[df['Actual'] != df['Prediction']]\n",
    "df_dif=df_dif.reset_index(drop=True)\n",
    "\n",
    "#add ids to satisfy Collect earth\n",
    "df_dif['PLOTID'] = range(0,len(df_dif))\n",
    "df_dif['SAMPLEID'] = range(0,len(df_dif))\n",
    "\n",
    "#create geodataframe\n",
    "gdf_dif = gpd.GeoDataFrame(\n",
    "        df_dif,\n",
    "        crs='epsg:4326',\n",
    "        geometry=gpd.points_from_xy(df_dif['lon'],df_dif['lat']))\n",
    "\n",
    "#convert to polys\n",
    "radius = 20\n",
    "gdf_dif = gdf_dif.to_crs('EPSG:6933')\n",
    "gdf_dif['geometry'] = gdf_dif['geometry'].buffer(radius).envelope\n",
    "gdf_dif = gdf_dif.to_crs('EPSG:4326')\n",
    "\n",
    "gdf_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_dif.to_file(folder+'indian_ocean_reference_sample_divergence_Ken.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
