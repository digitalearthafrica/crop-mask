{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall dea_ml -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -e dea_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "\n",
    "from dea_ml.core.feature_layer import create_features, get_xy_from_task\n",
    "from dea_ml.helpers.json_to_taskstr import extract_taskstr_from_geojson\n",
    "from dea_ml.helpers.io import download_file\n",
    "from dea_ml.core.africa_geobox import AfricaGeobox\n",
    "from dea_ml.core.predict_from_feature import PredictContext, predict_with_model\n",
    "from dea_ml.config.product_feature_config import FeaturePathConfig\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the feature layer fucntion\n",
    "from gm_mads_two_seasons import gm_mads_two_seasons\n",
    "feature_layer_function = gm_mads_two_seasons \n",
    "\n",
    "#define the post_processing function\n",
    "from post_processing import post_processing\n",
    "post_process = post_processing\n",
    "\n",
    "#define the chunks to use for dask\n",
    "dask_chunks = {'x':1500, 'y':1500}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate configuration class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dea_ml.config.product_feature_config.FeaturePathConfig"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the configuration\n",
    "config = FeaturePathConfig\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open tiles and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.tiles_geojson = '/home/jovyan/wa/u23/crop-mask/testing/eastern_cropmask/data/s2_tiles_eastern_aez.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open tiles geojson\n",
    "import fsspec\n",
    "\n",
    "tile_geojson_url= config.tiles_geojson \n",
    "# local_file = download_file(tile_geojson_url, '/tmp/tiles_geojson.json')\n",
    "\n",
    "with fsspec.open(tile_geojson_url) as fh:\n",
    "    tiles_geojson_dict = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_path = '/home/jovyan/wa/u23/crop-mask/testing/eastern_cropmask/results/gm_mads_two_seasons_ml_model_20210301.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', max_features='log2',\n",
      "                       n_estimators=400, n_jobs=31, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "# Open model\n",
    "ml_model_url = config.model_path\n",
    "with fsspec.open(ml_model_url) as fh:\n",
    "    model = joblib.load(fh)\n",
    "model.n_jobs = round(get_cpu_quota()) #update model with cpus available on this machine\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 'tasks' based on tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = extract_taskstr_from_geojson(time_range='2019-01--P6M', geojson=tiles_geojson_dict)\n",
    "len(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features for model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First generate a dictionary of geobox's for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 0\n"
     ]
    }
   ],
   "source": [
    "x, y = get_xy_from_task(tasks[0])\n",
    "print(x,y)\n",
    "\n",
    "geobox_dict = AfricaGeobox().geobox_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the feature layer function into the `create_features` function\n",
    "\n",
    "**Note:** This will take a couple of minutes to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (x: 4800, y: 4800)\n",
      "Coordinates:\n",
      "    time           datetime64[ns] 2019-07-02T11:59:59.999999\n",
      "  * y              (y) float64 9.599e+04 9.597e+04 9.595e+04 ... 50.0 30.0 10.0\n",
      "  * x              (x) float64 2.784e+06 2.784e+06 ... 2.88e+06 2.88e+06\n",
      "    spatial_ref    int32 6933\n",
      "    band           int64 1\n",
      "Data variables:\n",
      "    blue_S1        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    green_S1       (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    red_S1         (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    nir_S1         (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    swir_1_S1      (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    swir_2_S1      (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    red_edge_1_S1  (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    red_edge_2_S1  (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    red_edge_3_S1  (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    bcdev_S1       (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    edev_S1        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    sdev_S1        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    NDVI_S1        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    LAI_S1         (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    MNDWI_S1       (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    rain_S1        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    blue_S2        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    green_S2       (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    red_S2         (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    nir_S2         (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    swir_1_S2      (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    swir_2_S2      (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    red_edge_1_S2  (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    red_edge_2_S2  (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    red_edge_3_S2  (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    bcdev_S2       (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    edev_S2        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    sdev_S2        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    NDVI_S2        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    LAI_S2         (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    MNDWI_S2       (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    rain_S2        (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n",
      "    slope          (y, x) float32 dask.array<chunksize=(1500, 1500), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "subfld, geobox, data = create_features(x,\n",
    "                                       y,\n",
    "                                       config,\n",
    "                                       geobox_dict,\n",
    "                                       feature_func=gm_mads_two_seasons,\n",
    "                                       dask_chunks=dask_chunks) \n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run prediction\n",
    "\n",
    "**Note:** This will take a couple of minutes to run as the calculations are computed and brought into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pff = PredictContext(config, geobox_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predicting...\n",
      "   probabilities...\n"
     ]
    }
   ],
   "source": [
    "predicted = predict_with_model(config, model, data).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (x: 4800, y: 4800)\n",
      "Coordinates:\n",
      "  * x              (x) float64 2.784e+06 2.784e+06 ... 2.88e+06 2.88e+06\n",
      "  * y              (y) float64 9.599e+04 9.597e+04 9.595e+04 ... 50.0 30.0 10.0\n",
      "    spatial_ref    int32 0\n",
      "Data variables:\n",
      "    Predictions    (y, x) int64 dask.array<chunksize=(156, 4800), meta=np.ndarray>\n",
      "    Probabilities  (y, x) float64 dask.array<chunksize=(156, 4800), meta=np.ndarray>\n",
      "Attributes:\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.inproc - WARNING - Closing dangling queue in <InProc  local=inproc://10.95.120.221/4095/1 remote=inproc://10.95.120.221/4095/9>\n"
     ]
    }
   ],
   "source": [
    "# there some minor issue with dask_ml functions to raise the warning.\n",
    "predict = post_process(data, predicted, config, geobox)\n",
    "prob = predicted.Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'Probabilities' (y: 4800, x: 4800)>\n",
      "dask.array<reshape, shape=(4800, 4800), dtype=float64, chunksize=(157, 4800), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * x            (x) float64 2.784e+06 2.784e+06 2.784e+06 ... 2.88e+06 2.88e+06\n",
      "  * y            (y) float64 9.599e+04 9.597e+04 9.595e+04 ... 50.0 30.0 10.0\n",
      "    spatial_ref  int32 0\n",
      "Attributes:\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data\n",
    "- result will be in: \n",
    "```/home/jovyan/wa/u23/data/crop_mask_eastern/v0.1.7/x+029/y+000/2019```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pff.save_data(subfld, predict, prob, geobox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /home/jovyan/wa/u23/data/crop_mask_eastern/v0.1.7/x+029/y+000/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Either in this notebook or a seperate one, do the next steps: \n",
    "\n",
    "1. Database building\n",
    "2. AWS syncing to S3\n",
    "\n",
    "For command line operations in a notebook we can run commands using magic:\n",
    "        \n",
    "        e.g. !aws s3 mb s3://deafrica-data-dev-af --endpoint-url=htp://192.168.0.19:4566"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
