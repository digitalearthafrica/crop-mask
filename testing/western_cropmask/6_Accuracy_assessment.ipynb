{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy assessment of the Western Africa Cropland Mask<img align=\"right\" src=\"../figs/DE_Africa_Logo_Stacked_RGB_small.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "Now that we have run classifications for the Western Africa AEZ, its time to conduct an accuracy assessment. The data used for assessing the accuracy was collected previously and set aside. Its stored in the data/ folder: `data/Validation_samples.shp` \n",
    "\n",
    "This notebook will output a `confusion error matrix` containing Overall, Producer's, and User's accuracy, along with the F1 score for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/geopandas/_compat.py:88: UserWarning: The Shapely GEOS version (3.7.2-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from sklearn.metrics import f1_score\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "\n",
    "# sys.path.append('../../Scripts')\n",
    "from deafrica_tools.spatial import zonal_stats_parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters\n",
    "\n",
    "* `pred_tif` : a binary classification of crop/no-crop output by the ML script.\n",
    "* `grd_truth` : a shapefile containing crop/no-crop points to serve as the \"ground-truth\" dataset\n",
    "* `aez_region` : a shapefile used to limit the ground truth points to the region where the model has classified crop/non-crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tif = \"results/classifications/20210525/Western_gm_mads_two_seasons_20210525_mosaic_clipped.tif\"\n",
    "# grd_truth = '../pre-post_processing/data/training_validation/GFSAD2015/cropland_prelim_validation_GFSAD.shp'\n",
    "grd_truth = 'data/validation_samples.shp'\n",
    "# aez_region = 'data/Western.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets\n",
    "\n",
    "`Ground truth points`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground truth shapefile\n",
    "ground_truth = gpd.read_file(grd_truth).to_crs('EPSG:6933')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>smpl_sampl</th>\n",
       "      <th>smpl_gfsad</th>\n",
       "      <th>Actual</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.466886</td>\n",
       "      <td>12.261465</td>\n",
       "      <td>1533</td>\n",
       "      <td>0</td>\n",
       "      <td>non-crop</td>\n",
       "      <td>POINT (720452.101 1552635.612)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.864863</td>\n",
       "      <td>11.922979</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>non-crop</td>\n",
       "      <td>POINT (1241282.778 1510387.311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.822080</td>\n",
       "      <td>6.917926</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>non-crop</td>\n",
       "      <td>POINT (754723.435 880456.813)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.899884</td>\n",
       "      <td>8.030400</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>non-crop</td>\n",
       "      <td>POINT (955202.942 1021202.641)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.725412</td>\n",
       "      <td>9.702883</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>crop</td>\n",
       "      <td>POINT (-552423.751 1232076.864)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lon        lat  smpl_sampl  smpl_gfsad    Actual  \\\n",
       "0   7.466886  12.261465        1533           0  non-crop   \n",
       "1  12.864863  11.922979         458           0  non-crop   \n",
       "2   7.822080   6.917926         189           0  non-crop   \n",
       "3   9.899884   8.030400        2048           0  non-crop   \n",
       "4  -5.725412   9.702883         156           0      crop   \n",
       "\n",
       "                          geometry  \n",
       "0   POINT (720452.101 1552635.612)  \n",
       "1  POINT (1241282.778 1510387.311)  \n",
       "2    POINT (754723.435 880456.813)  \n",
       "3   POINT (955202.942 1021202.641)  \n",
       "4  POINT (-552423.751 1232076.864)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the class column to 'actual'\n",
    "ground_truth = ground_truth.rename(columns={'Class':'Actual'})\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reclassify 'Actual' column to match the raster values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open shapefile\n",
    "# aez=gpd.read_file(aez_region).to_crs('EPSG:6933')\n",
    "# # clip points to region\n",
    "# ground_truth = gpd.overlay(ground_truth,aez, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth['Actual'] = np.where(ground_truth['Actual']=='non-crop', 0, ground_truth['Actual'])\n",
    "ground_truth['Actual'] = np.where(ground_truth['Actual']=='crop', 1, ground_truth['Actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell if point sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Point sampling of raster for validation purpose\n",
    "prediction = rasterio.open(pred_tif)\n",
    "coords = [(x,y) for x, y in zip(ground_truth.geometry.x, ground_truth.geometry.y)]\n",
    "# Sample the raster at every point location and store values in DataFrame\n",
    "ground_truth['Prediction'] = [int(x[0]) for x in prediction.sample(coords)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next two cells if polygon sampling\n",
    "#### Convert points into polygons\n",
    "\n",
    "When the validation data was collected, 40x40m polygons were evaluated as either crop/non-crop rather than points, so we want to sample the raster using the same small polygons. We'll find the majority or 'mode' statistic within the polygon and use that to compare with the validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set radius (in metres) around points\n",
    "radius = 20\n",
    "\n",
    "#convert to equal area to set polygon size in metres\n",
    "ground_truth = ground_truth\n",
    "\n",
    "#create circle buffer around points, then find envelope\n",
    "ground_truth['geometry'] = ground_truth['geometry'].buffer(radius).envelope\n",
    "\n",
    "#export to file for use in zonal-stats\n",
    "ground_truth.to_file(grd_truth[:-4]+\"_poly.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate zonal statistics\n",
    "\n",
    "We want to know what the majority pixel value is inside each validation polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats_parallel(shp=grd_truth[:-4]+\"_poly.shp\",\n",
    "                    raster=pred_tif,\n",
    "                    statistics=['majority'],\n",
    "                    out_shp=grd_truth[:-4]+\"_poly.shp\",\n",
    "                    ncpus=round(get_cpu_quota()),\n",
    "                    nodata=-999)\n",
    "\n",
    "#read in the results\n",
    "x=gpd.read_file(grd_truth[:-4]+\"_poly.shp\")\n",
    "\n",
    "#add result to original ground truth array\n",
    "ground_truth['Prediction'] = x['majority'].astype(np.int16)\n",
    "\n",
    "#Remove the temporary shapefile we made\n",
    "[os.remove(i) for i in glob.glob(grd_truth[:-4]+\"_poly\"+'*')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>206</td>\n",
       "      <td>94</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction    0   1  All\n",
       "Actual                  \n",
       "0           180  20  200\n",
       "1            26  74  100\n",
       "All         206  94  300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(ground_truth['Actual'],\n",
    "                               ground_truth['Prediction'],\n",
    "                               rownames=['Actual'],\n",
    "                               colnames=['Prediction'],\n",
    "                               margins=True)\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate User's and Producer's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Producer's Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix[\"Producer's\"] = [confusion_matrix.loc[0, 0] / confusion_matrix.loc[0, 'All'] * 100,\n",
    "                              confusion_matrix.loc[1, 1] / confusion_matrix.loc[1, 'All'] * 100,\n",
    "                              np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`User's Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_accuracy = pd.Series([confusion_matrix[0][0] / confusion_matrix[0]['All'] * 100,\n",
    "                                confusion_matrix[1][1] / confusion_matrix[1]['All'] * 100]\n",
    "                         ).rename(\"User's\")\n",
    "\n",
    "confusion_matrix = confusion_matrix.append(users_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Overall Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.loc[\"User's\",\"Producer's\"] = (confusion_matrix.loc[0, 0] + \n",
    "                                                confusion_matrix.loc[1, 1]) / confusion_matrix.loc['All', 'All'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`F1 Score`\n",
    "\n",
    "The F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall), and is calculated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Fscore} = 2 \\times \\frac{\\text{UA} \\times \\text{PA}}{\\text{UA} + \\text{PA}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where UA = Users Accuracy, and PA = Producer's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = pd.Series([(2*(confusion_matrix.loc[\"User's\", 0]*confusion_matrix.loc[0, \"Producer's\"]) / (confusion_matrix.loc[\"User's\", 0]+confusion_matrix.loc[0, \"Producer's\"])) / 100,\n",
    "                    f1_score(ground_truth['Actual'].astype(np.int8), ground_truth['Prediction'].astype(np.int8), average='binary')]\n",
    "                         ).rename(\"F-score\")\n",
    "\n",
    "confusion_matrix = confusion_matrix.append(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Confusion Matrix\n",
    "\n",
    "* Limit decimal places,\n",
    "* Add readable class names\n",
    "* Remove non-sensical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "confusion_matrix = confusion_matrix.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename booleans to class names\n",
    "confusion_matrix = confusion_matrix.rename(columns={0:'Non-crop', 1:'Crop', 'All':'Total'},\n",
    "                                            index={0:'Non-crop', 1:'Crop', 'All':'Total'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the nonsensical values in the table\n",
    "confusion_matrix.loc[\"User's\", 'Total'] = '--'\n",
    "confusion_matrix.loc['Total', \"Producer's\"] = '--'\n",
    "confusion_matrix.loc[\"F-score\", 'Total'] = '--'\n",
    "confusion_matrix.loc[\"F-score\", \"Producer's\"] = '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>Non-crop</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Total</th>\n",
       "      <th>Producer's</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-crop</th>\n",
       "      <td>180.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crop</th>\n",
       "      <td>26.00</td>\n",
       "      <td>74.00</td>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>206.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>300</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User's</th>\n",
       "      <td>87.38</td>\n",
       "      <td>78.72</td>\n",
       "      <td>--</td>\n",
       "      <td>84.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction  Non-crop   Crop Total Producer's\n",
       "Actual                                      \n",
       "Non-crop      180.00  20.00   200         90\n",
       "Crop           26.00  74.00   100         74\n",
       "Total         206.00  94.00   300         --\n",
       "User's         87.38  78.72    --      84.67\n",
       "F-score         0.89   0.76    --         --"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.to_csv('results/Eastern_confusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This is the last notebook in the `Western Africa Cropland Mask` workflow! To revist any of the other notebooks, use the links below.\n",
    "\n",
    "1. [Extract_training_data](1_Extract_training_data.ipynb) \n",
    "2. [Inspect_training_data](2_Inspect_training_data.ipynb)\n",
    "3. [Train_fit_evaluate_classifier](3_Train_fit_evaluate_classifier.ipynb)\n",
    "4. [Predict](4_Predict.ipynb)\n",
    "5. [Object-based_filtering](5_Object-based_filtering.ipynb)\n",
    "6. **Accuracy_assessment (this notebook)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** Dec 2020\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
